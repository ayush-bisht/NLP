{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qa_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxltZlPG85Xn",
        "outputId": "a7dcc1e2-7719-4e6f-e2b1-2d6f0c1434e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Transformers installation\n",
        "! pip install transformers\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers.data.processors.squad import SquadV2Processor\n",
        "import json\n",
        "from pprint import pprint\n",
        "import regex as re\n",
        "import collections\n",
        "from transformers.data.metrics.squad_metrics import squad_evaluate\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 60.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=90642109ffe2606e9366010de776d46bf547179991830d80730ef7dc8a3ab9f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N31wygR285Z6",
        "outputId": "3f965daa-a54d-49ea-e73f-49ee6d795d24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! mkdir squad\n",
        "! wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad/train-v2.0.json\n",
        "! wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O squad/dev-v2.0.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-14 14:40:19--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘squad/train-v2.0.json’\n",
            "\n",
            "squad/train-v2.0.js 100%[===================>]  40.17M   104MB/s    in 0.4s    \n",
            "\n",
            "2020-11-14 14:40:20 (104 MB/s) - ‘squad/train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2020-11-14 14:40:20--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘squad/dev-v2.0.json’\n",
            "\n",
            "squad/dev-v2.0.json 100%[===================>]   4.17M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-11-14 14:40:20 (41.8 MB/s) - ‘squad/dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_egDN8My0Xk",
        "outputId": "3fe0520c-2803-4d33-b469-904af5f36dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhS3HSwFcJm2"
      },
      "source": [
        "def display_example(qid):    \n",
        "  from pprint import pprint\n",
        "\n",
        "  idx = qid_to_example_index[qid]\n",
        "  q = examples[idx].question_text\n",
        "  c = examples[idx].context_text\n",
        "  a = [answer['text'] for answer in examples[idx].answers]\n",
        "  \n",
        "  print(f'Example {idx} of {len(examples)}\\n---------------------')\n",
        "  print(f\"Q: {q}\\n\")\n",
        "  print(\"Context:\")\n",
        "  pprint(c)\n",
        "  print(f\"\\nTrue Answers:\\n{a}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQnh7P309umi"
      },
      "source": [
        "question_answer_pair = {\n",
        "    \"when\": ['before', 'after', 'about', 'around', 'from', 'during', 'in'],\n",
        "    \"where\": ['in', 'at', 'on', 'behind', 'from', 'through', 'between', 'throughout'],\n",
        "    \"whose\": [\"'s\"],\n",
        "    \"which\": [\"the\"]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICLDWfJaENAU"
      },
      "source": [
        "def question_type(question):\n",
        "  q_type = \"other\"\n",
        "  for q in question_answer_pair.keys():\n",
        "    temp_type = re.findall(q, question)\n",
        "    if len(temp_type) > 0:\n",
        "      q_type = temp_type[0]\n",
        "  return q_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "033ztDDkHVNw"
      },
      "source": [
        "def answer_probability(question, answer, start_logit):\n",
        "  start_text = answer.split()[0]\n",
        "  q_type = question_type(question.lower())\n",
        "  #print(q_type)\n",
        "  if q_type == \"other\":\n",
        "    return start_logit\n",
        "  else:\n",
        "    probable_answers = question_answer_pair[q_type]\n",
        "    if q_type == \"whose\":\n",
        "      if re.findall(probable_answers[0],start_text):\n",
        "        return start_logit + 1.5        \n",
        "    else:      \n",
        "      if start_text in probable_answers:\n",
        "        return start_logit + 1.5\n",
        "  \n",
        "  return start_logit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqwNJA6wQMSB"
      },
      "source": [
        "def to_list(tensor):\n",
        "  return tensor.detach().cpu().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rwHTbqkRXpW"
      },
      "source": [
        "def get_prediction(qid, model, tokenizer, examples):\n",
        "  # given a question id (qas_id or qid), load the example, get the model outputs and generate an answer\n",
        "  question = examples[qid_to_example_index[qid]].question_text\n",
        "  \n",
        "  context = examples[qid_to_example_index[qid]].context_text\n",
        "\n",
        "  inputs = tokenizer.encode_plus(question, context, return_tensors='pt', truncation=True, max_length=384)\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "  model.to(device)\n",
        "  start_logits, end_logits = model(**inputs.to(device))\n",
        "\n",
        "  # convert our start and end logit tensors to lists\n",
        "  start_logits = to_list(start_logits)[0]\n",
        "  end_logits = to_list(end_logits)[0]\n",
        "\n",
        "  # sort our start and end logits from largest to smallest, keeping track of the index\n",
        "  start_idx_and_logit = sorted(enumerate(start_logits), key=lambda x: x[1], reverse=True)\n",
        "  end_idx_and_logit = sorted(enumerate(end_logits), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # select the top n (in this case, 5)\n",
        "  start_indexes = [idx for idx, logit in start_idx_and_logit[:5]]\n",
        "  end_indexes = [idx for idx, logit in end_idx_and_logit[:5]]\n",
        "\n",
        "  # convert the token ids from a tensor to a list\n",
        "  tokens = to_list(inputs['input_ids'])[0]\n",
        "\n",
        "  # question tokens are defined as those between the CLS token (101, at position 0) and first SEP (102) token \n",
        "  question_indexes = [i+1 for i, token in enumerate(tokens[1:tokens.index(102)])]\n",
        "\n",
        "  # keep track of all preliminary predictions\n",
        "  PrelimPrediction = collections.namedtuple( \n",
        "      \"PrelimPrediction\", [\"start_index\", \"end_index\", \"start_logit\", \"end_logit\"]\n",
        "  )\n",
        "\n",
        "  prelim_preds = []\n",
        "  for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "      # throw out invalid predictions\n",
        "      if start_index in question_indexes:\n",
        "        continue\n",
        "      if end_index in question_indexes:\n",
        "        continue\n",
        "      if end_index < start_index:\n",
        "        continue\n",
        "      prelim_preds.append(\n",
        "        PrelimPrediction(\n",
        "            start_index = start_index,\n",
        "            end_index = end_index,\n",
        "            start_logit = start_logits[start_index],\n",
        "            end_logit = end_logits[end_index]\n",
        "        )\n",
        "      )\n",
        "\n",
        "\n",
        "    # keep track of all best predictions\n",
        "  BestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "      \"BestPrediction\", [\"text\", \"start_logit\", \"end_logit\"]\n",
        "  )\n",
        "\n",
        "  nbest = []\n",
        "  seen_predictions = []\n",
        "  for pred in prelim_preds:\n",
        "      \n",
        "      # for now we only care about the top 5 best predictions\n",
        "      if len(nbest) >= 5: \n",
        "          break\n",
        "          \n",
        "      # loop through predictions according to their start index\n",
        "      if pred.start_index > 0: # non-null answers have start_index > 0\n",
        "\n",
        "          text = tokenizer.convert_tokens_to_string(\n",
        "              tokenizer.convert_ids_to_tokens(\n",
        "                  tokens[pred.start_index:pred.end_index+1]\n",
        "              )\n",
        "          )\n",
        "          # clean whitespace\n",
        "          text = text.strip()\n",
        "          text = \" \".join(text.split())\n",
        "\n",
        "          if text in seen_predictions:\n",
        "              continue\n",
        "          # flag this text as being seen -- if we see it again, don't add it to the nbest list\n",
        "          seen_predictions.append(text) \n",
        "\n",
        "          # add this text prediction to a pruned list of the top 5 best predictions\n",
        "          nbest.append(BestPrediction(text=text, start_logit=pred.start_logit, end_logit=pred.end_logit))\n",
        "\n",
        "  # and don't forget -- include the null answer!\n",
        "  nbest.append(BestPrediction(text=\"\", start_logit=start_logits[0], end_logit=end_logits[0]))\n",
        "\n",
        "  # compute the null score as the sum of the [CLS] token logits\n",
        "  score_null = start_logits[0] + end_logits[0]\n",
        "\n",
        "  # compute the difference between the null score and the best non-null score\n",
        "  score_diff = score_null - nbest[0].start_logit - nbest[0].end_logit\n",
        "  \n",
        "  return score_diff, nbest[0].text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70zFLs157WF-"
      },
      "source": [
        "def get_prediction_postprocessing(qid, model, tokenizer, examples):\n",
        "  # given a question id (qas_id or qid), load the example, get the model outputs and generate an answer\n",
        "  question = examples[qid_to_example_index[qid]].question_text\n",
        "  \n",
        "  context = examples[qid_to_example_index[qid]].context_text\n",
        "\n",
        "\n",
        "  inputs = tokenizer.encode_plus(question, context, return_tensors='pt', truncation=True, max_length=384)\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "  model.to(device)\n",
        "  start_logits, end_logits = model(**inputs.to(device))\n",
        "\n",
        "  # convert our start and end logit tensors to lists\n",
        "  start_logits = to_list(start_logits)[0]\n",
        "  end_logits = to_list(end_logits)[0]\n",
        "\n",
        "  # sort our start and end logits from largest to smallest, keeping track of the index\n",
        "  start_idx_and_logit = sorted(enumerate(start_logits), key=lambda x: x[1], reverse=True)\n",
        "  end_idx_and_logit = sorted(enumerate(end_logits), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # select the top n (in this case, 5)\n",
        "  start_indexes = [idx for idx, logit in start_idx_and_logit[:5]]\n",
        "  end_indexes = [idx for idx, logit in end_idx_and_logit[:5]]\n",
        "\n",
        "  # convert the token ids from a tensor to a list\n",
        "  tokens = to_list(inputs['input_ids'])[0]\n",
        "  question_indexes = [i+1 for i, token in enumerate(tokens[1:tokens.index(102)])]\n",
        "\n",
        "  # keep track of all preliminary predictions\n",
        "  PrelimPrediction = collections.namedtuple( \n",
        "      \"PrelimPrediction\", [\"start_index\", \"end_index\", \"start_logit\", \"end_logit\"]\n",
        "  )\n",
        "\n",
        "  prelim_preds = []\n",
        "  for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "      # throw out invalid predictions\n",
        "      if start_index in question_indexes:\n",
        "        continue\n",
        "      if end_index in question_indexes:\n",
        "        continue\n",
        "      if end_index < start_index:\n",
        "        continue\n",
        "      prelim_preds.append(\n",
        "        PrelimPrediction(\n",
        "            start_index = start_index,\n",
        "            end_index = end_index,\n",
        "            start_logit = start_logits[start_index],\n",
        "            end_logit = end_logits[end_index]\n",
        "        )\n",
        "      )\n",
        "\n",
        "    # keep track of all best predictions\n",
        "  BestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "      \"BestPrediction\", [\"text\", \"start_logit\", \"end_logit\"]\n",
        "  )\n",
        "\n",
        "  nbest = []\n",
        "  seen_predictions = []\n",
        "  for pred in prelim_preds:\n",
        "    if pred.start_index > 0: # non-null answers have start_index > 0\n",
        "\n",
        "      text = tokenizer.convert_tokens_to_string(\n",
        "          tokenizer.convert_ids_to_tokens(\n",
        "              tokens[pred.start_index:pred.end_index+1]\n",
        "          )\n",
        "      )\n",
        "      # clean whitespace\n",
        "      text = text.strip()\n",
        "      text = \" \".join(text.split())\n",
        "\n",
        "      if text in seen_predictions:\n",
        "          continue\n",
        "\n",
        "      # flag this text as being seen -- if we see it again, don't add it to the nbest list\n",
        "      seen_predictions.append(text) \n",
        "\n",
        "      # add this text prediction to a pruned list of the top 5 best predictions\n",
        "      new_start_logit = answer_probability(question, text, pred.start_logit)\n",
        "      if new_start_logit == pred.start_logit:\n",
        "        nbest.append(BestPrediction(text=text, start_logit=pred.start_logit, end_logit=pred.end_logit))\n",
        "      else:\n",
        "        nbest.append(BestPrediction(text=text, start_logit=new_start_logit, end_logit=pred.end_logit))\n",
        "      \n",
        "\n",
        "  nbest = sorted(nbest, key=lambda x: x.start_logit+x.end_logit, reverse=True)\n",
        "  nbest = nbest[:5]\n",
        "  # and don't forget -- include the null answer!\n",
        "  nbest.append(BestPrediction(text=\"\", start_logit=start_logits[0], end_logit=end_logits[0]))\n",
        "  \n",
        "  # compute the null score as the sum of the [CLS] token logits\n",
        "  score_null = start_logits[0] + end_logits[0]\n",
        "  # compute the difference between the null score and the best non-null score\n",
        "  score_diff = score_null - nbest[0].start_logit - nbest[0].end_logit\n",
        "  \n",
        "  return score_diff, nbest[0].text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r1WRureTP9u"
      },
      "source": [
        "def dev_set_testing(file_dir, model, tokenizer, examples, answer_qids, no_answer_qids):\n",
        "  score_diff_dev1 = {}\n",
        "  predictions1 = {}\n",
        "  score_diff_dev2 = {}\n",
        "  predictions2 = {}\n",
        "\n",
        "  for i in range(len(answer_qids)):\n",
        "    score_diff_dev1[answer_qids[i]], predictions1[answer_qids[i]] = (get_prediction(answer_qids[i], model, tokenizer, examples))\n",
        "    score_diff_dev2[answer_qids[i]], predictions2[answer_qids[i]] = (get_prediction_postprocessing(answer_qids[i], model, tokenizer, examples))\n",
        "  \n",
        "  for i in range(len(no_answer_qids)):\n",
        "    score_diff_dev1[no_answer_qids[i]], predictions1[no_answer_qids[i]] = (get_prediction(no_answer_qids[i], model, tokenizer, examples))\n",
        "    score_diff_dev2[no_answer_qids[i]], predictions2[no_answer_qids[i]] = (get_prediction_postprocessing(no_answer_qids[i], model, tokenizer, examples))\n",
        "\n",
        "  filename_null_odds_1 = file_dir + 'null_odds_1.json'\n",
        "  filename_predictions_1 = file_dir + 'predictions_1.json'\n",
        "  filename_null_odds_2 = file_dir + 'null_odds_2.json'\n",
        "  filename_predictions_2 = file_dir + 'predictions_2.json'\n",
        "\n",
        "  with open(filename_null_odds_1, 'w') as outfile:\n",
        "    json.dump(score_diff_dev1, outfile)\n",
        "\n",
        "  with open(filename_predictions_1, 'w') as outfile:\n",
        "      json.dump(predictions1, outfile)\n",
        "\n",
        "  with open(filename_null_odds_2, 'w') as outfile:\n",
        "      json.dump(score_diff_dev2, outfile)\n",
        "\n",
        "  with open(filename_predictions_2, 'w') as outfile:\n",
        "      json.dump(predictions2, outfile)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOSkeRhYLX2Z"
      },
      "source": [
        "def evaluate_model(file_dir, model, tokenizer, examples, answer_qids, no_answer_qids):\n",
        "  filename_null_odds_1 = file_dir + 'null_odds_1.json'\n",
        "  filename_predictions_1 = file_dir + 'predictions_1.json'\n",
        "  filename_null_odds_2 = file_dir + 'null_odds_2.json'\n",
        "  filename_predictions_2 = file_dir + 'predictions_2.json'\n",
        "  null_odds1 = json.load(open(filename_null_odds_1, 'rb'))\n",
        "  predictions1 = json.load(open(filename_predictions_1, 'rb'))\n",
        "  null_odds2 = json.load(open(filename_null_odds_2, 'rb'))\n",
        "  predictions2 = json.load(open(filename_predictions_2, 'rb'))\n",
        "\n",
        "  # the default threshold is set to 1.0 -- we'll leave it there for now\n",
        "  results_default_thresh = get_evaluation_metrics(dev_examples, predictions2, null_odds2, 1.0)\n",
        "  best_f1_thresh = results_default_thresh['best_f1_thresh']\n",
        "\n",
        "  results_f1_thresh = get_evaluation_metrics(dev_examples, predictions2, null_odds2, best_f1_thresh)\n",
        "  print('METRICS FOR DEV SET WITHOUT POSTPROCESSING')\n",
        "  pprint(results_f1_thresh)\n",
        "  \n",
        "  # the default threshold is set to 1.0 -- we'll leave it there for now\n",
        "  results_default_thresh = get_evaluation_metrics(dev_examples, predictions1, null_odds1, 1.0)\n",
        "  best_f1_thresh = results_default_thresh['best_f1_thresh']\n",
        "  results_f1_thresh = get_evaluation_metrics(dev_examples, predictions1, null_odds1, best_f1_thresh)\n",
        "  print('METRICS FOR DEV SET WITH POSTPROCESSING')\n",
        "  pprint(results_f1_thresh)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng0FPf5DTq-A"
      },
      "source": [
        "def get_evaluation_metrics(examples, predictions, null_odds, prob_threshhold=1):\n",
        "  return squad_evaluate(examples, predictions, no_answer_probs=null_odds, \n",
        "                                        no_answer_probability_threshold=prob_threshhold)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42Z6lxF5RyL9"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5trHoaLN1g7"
      },
      "source": [
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/My Drive/nlp_dataset/bert-base-uncased\")\n",
        "bert_model = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/My Drive/nlp_dataset/bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFs_XVyHNvdy"
      },
      "source": [
        "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/My Drive/nlp_dataset/distilbert-base-uncased\")\n",
        "distilbert_model = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/My Drive/nlp_dataset/distilbert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITdKp_yZWRMM",
        "outputId": "35e7d069-adfc-4869-ed54-1bb6909bd9ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this processor loads the SQuAD2.0 dev set examples\n",
        "processor = SquadV2Processor()\n",
        "dev_examples = processor.get_dev_examples(\"/content/squad\", filename=\"dev-v2.0.json\")\n",
        "print(len(dev_examples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:03<00:00,  8.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWwrk2hbb1mh"
      },
      "source": [
        "# generate some maps to help us identify examples of interest\n",
        "qid_to_example_index = {example.qas_id: i for i, example in enumerate(dev_examples)}\n",
        "qid_to_has_answer = {example.qas_id: bool(example.answers) for example in dev_examples}\n",
        "answer_qids = [qas_id for qas_id, has_answer in qid_to_has_answer.items() if has_answer]\n",
        "no_answer_qids = [qas_id for qas_id, has_answer in qid_to_has_answer.items() if not has_answer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqvhHQ9q061Y"
      },
      "source": [
        "BERT TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKCLk3lQb2vc"
      },
      "source": [
        "dev_set_testing(\"/content/drive/My Drive/nlp_dataset/bert-base-uncased/\", \n",
        "                bert_model, bert_tokenizer, dev_examples, answer_qids, no_answer_qids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY7OJTPcNSZ1",
        "outputId": "14aee0e6-f978-4e5c-b9ff-d434da43ead3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_model(\"/content/drive/My Drive/nlp_dataset/bert-base-uncased/\", \n",
        "                bert_model, bert_tokenizer, dev_examples, answer_qids, no_answer_qids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "METRICS FOR DEV SET WITHOUT POSTPROCESSING\n",
            "OrderedDict([('exact', 69.34220500294786),\n",
            "             ('f1', 73.80082311322276),\n",
            "             ('total', 11873),\n",
            "             ('HasAns_exact', 60.239541160593795),\n",
            "             ('HasAns_f1', 69.16956356668244),\n",
            "             ('HasAns_total', 5928),\n",
            "             ('NoAns_exact', 78.4188393608074),\n",
            "             ('NoAns_f1', 78.4188393608074),\n",
            "             ('NoAns_total', 5945),\n",
            "             ('best_exact', 69.52749936831466),\n",
            "             ('best_exact_thresh', -6.801867485046387),\n",
            "             ('best_f1', 73.8008231132222),\n",
            "             ('best_f1_thresh', -3.7661972045898438)])\n",
            "METRICS FOR DEV SET WITH POSTPROCESSING\n",
            "OrderedDict([('exact', 69.43485218563126),\n",
            "             ('f1', 73.8232516483557),\n",
            "             ('total', 11873),\n",
            "             ('HasAns_exact', 60.35762483130904),\n",
            "             ('HasAns_f1', 69.14700857303089),\n",
            "             ('HasAns_total', 5928),\n",
            "             ('NoAns_exact', 78.4861227922624),\n",
            "             ('NoAns_f1', 78.4861227922624),\n",
            "             ('NoAns_total', 5945),\n",
            "             ('best_exact', 69.63699149330414),\n",
            "             ('best_exact_thresh', -6.73000955581665),\n",
            "             ('best_f1', 73.82325164835513),\n",
            "             ('best_f1_thresh', -3.7661972045898438)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV022psb09mL"
      },
      "source": [
        "DISTILBERT TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaCho02q1MJE"
      },
      "source": [
        "dev_set_testing(\"/content/drive/My Drive/nlp_dataset/distilbert-base-uncased/\", \n",
        "                distilbert_model, distilbert_tokenizer, dev_examples, answer_qids, no_answer_qids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1HhMO8bR7iC",
        "outputId": "6334c41c-34a1-42c6-e5d8-3d0a7711fc75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_model(\"/content/drive/My Drive/nlp_dataset/distilbert-base-uncased/\", \n",
        "                bert_model, bert_tokenizer, dev_examples, answer_qids, no_answer_qids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "METRICS FOR DEV SET WITHOUT POSTPROCESSING\n",
            "OrderedDict([('exact', 64.57508633032931),\n",
            "             ('f1', 68.54706579411912),\n",
            "             ('total', 11873),\n",
            "             ('HasAns_exact', 53.9136302294197),\n",
            "             ('HasAns_f1', 61.86897978636555),\n",
            "             ('HasAns_total', 5928),\n",
            "             ('NoAns_exact', 75.20605550883096),\n",
            "             ('NoAns_f1', 75.20605550883096),\n",
            "             ('NoAns_total', 5945),\n",
            "             ('best_exact', 64.71826833993093),\n",
            "             ('best_exact_thresh', -5.177046895027161),\n",
            "             ('best_f1', 68.54706579411919),\n",
            "             ('best_f1_thresh', -3.7676496505737305)])\n",
            "METRICS FOR DEV SET WITH POSTPROCESSING\n",
            "OrderedDict([('exact', 64.62562115724754),\n",
            "             ('f1', 68.53062384308238),\n",
            "             ('total', 11873),\n",
            "             ('HasAns_exact', 53.93049932523617),\n",
            "             ('HasAns_f1', 61.75170325386568),\n",
            "             ('HasAns_total', 5928),\n",
            "             ('NoAns_exact', 75.2901597981497),\n",
            "             ('NoAns_f1', 75.2901597981497),\n",
            "             ('NoAns_total', 5945),\n",
            "             ('best_exact', 64.78564810915523),\n",
            "             ('best_exact_thresh', -5.177046895027161),\n",
            "             ('best_f1', 68.53062384308244),\n",
            "             ('best_f1_thresh', -3.7676496505737305)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axtem7xfUSpM"
      },
      "source": [
        "TESTING ON AUGMENTED DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIRXFYaZUquU",
        "outputId": "923a31c2-2c2b-4bf9-eed7-6e77746e0f3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this load augmented data\n",
        "processor = SquadV2Processor()\n",
        "dev_examples = processor.get_dev_examples(\"/content/drive/My Drive/nlp_dataset/\", filename=\"augmented_dev.json\")\n",
        "print(len(dev_examples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:04<00:00,  7.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFxtOfuOUquy"
      },
      "source": [
        "# generate some maps to help us identify examples of interest\n",
        "qid_to_example_index = {example.qas_id: i for i, example in enumerate(dev_examples)}\n",
        "qid_to_has_answer = {example.qas_id: bool(example.answers) for example in dev_examples}\n",
        "answer_qids = [qas_id for qas_id, has_answer in qid_to_has_answer.items() if has_answer]\n",
        "no_answer_qids = [qas_id for qas_id, has_answer in qid_to_has_answer.items() if not has_answer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl4-jfL7T_C2"
      },
      "source": [
        "dev_set_testing(\"/content/drive/My Drive/nlp_dataset/bert-base-uncased/\", \n",
        "                bert_model, bert_tokenizer, dev_examples, answer_qids, no_answer_qids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TtCDy2rT_DT",
        "outputId": "1bdb2d85-b8bf-46b3-b3ee-2331a2ee6a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_model(\"/content/drive/My Drive/nlp_dataset/bert-base-uncased/\", \n",
        "                bert_model, bert_tokenizer, dev_examples, answer_qids, no_answer_qids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "METRICS FOR DEV SET WITHOUT POSTPROCESSING\n",
            "OrderedDict([('exact', 51.96664701423398),\n",
            "             ('f1', 57.508129920756645),\n",
            "             ('total', 11873),\n",
            "             ('HasAns_exact', 18.387314439946017),\n",
            "             ('HasAns_f1', 29.48617182003078),\n",
            "             ('HasAns_total', 5928),\n",
            "             ('NoAns_exact', 85.44995794785534),\n",
            "             ('NoAns_f1', 85.44995794785534),\n",
            "             ('NoAns_total', 5945),\n",
            "             ('best_exact', 53.128948033352984),\n",
            "             ('best_exact_thresh', -9.303107738494873),\n",
            "             ('best_f1', 57.474440036144685),\n",
            "             ('best_f1_thresh', -3.6766037940979004)])\n",
            "METRICS FOR DEV SET WITH POSTPROCESSING\n",
            "OrderedDict([('exact', 51.98349195654005),\n",
            "             ('f1', 57.48830322603369),\n",
            "             ('total', 11873),\n",
            "             ('HasAns_exact', 18.42105263157895),\n",
            "             ('HasAns_f1', 29.44646157265462),\n",
            "             ('HasAns_total', 5928),\n",
            "             ('NoAns_exact', 85.44995794785534),\n",
            "             ('NoAns_f1', 85.44995794785534),\n",
            "             ('NoAns_total', 5945),\n",
            "             ('best_exact', 53.13737050450602),\n",
            "             ('best_exact_thresh', -9.303107738494873),\n",
            "             ('best_f1', 57.45461334142172),\n",
            "             ('best_f1_thresh', -3.6766037940979004)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40ugk6f-T_Dk"
      },
      "source": [
        "dev_set_testing(\"/content/drive/My Drive/nlp_dataset/distilbert-base-uncased/\", \n",
        "                distilbert_model, distilbert_tokenizer, dev_examples, answer_qids, no_answer_qids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O-Cg-hPT_D3",
        "outputId": "6bc9407e-a264-48bc-e3e6-af656a285ced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_model(\"/content/drive/My Drive/nlp_dataset/distilbert-base-uncased/\", \n",
        "                bert_model, bert_tokenizer, dev_examples, answer_qids, no_answer_qids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "METRICS FOR DEV SET WITHOUT POSTPROCESSING\n",
            "OrderedDict([('exact', 51.06544260085909),\n",
            "             ('f1', 55.48120675166491),\n",
            "             ('total', 11873),\n",
            "             ('HasAns_exact', 15.24966261808367),\n",
            "             ('HasAns_f1', 24.093854210950795),\n",
            "             ('HasAns_total', 5928),\n",
            "             ('NoAns_exact', 86.77880571909168),\n",
            "             ('NoAns_f1', 86.77880571909168),\n",
            "             ('NoAns_total', 5945),\n",
            "             ('best_exact', 52.08456161037648),\n",
            "             ('best_exact_thresh', -8.188229084014893),\n",
            "             ('best_f1', 55.455939338206),\n",
            "             ('best_f1_thresh', -3.447478547692299)])\n",
            "METRICS FOR DEV SET WITH POSTPROCESSING\n",
            "OrderedDict([('exact', 51.579213341194304),\n",
            "             ('f1', 55.44090730463834),\n",
            "             ('total', 11873),\n",
            "             ('HasAns_exact', 14.018218623481781),\n",
            "             ('HasAns_f1', 21.752680908901812),\n",
            "             ('HasAns_total', 5928),\n",
            "             ('NoAns_exact', 89.03280067283431),\n",
            "             ('NoAns_f1', 89.03280067283431),\n",
            "             ('NoAns_total', 5945),\n",
            "             ('best_exact', 52.07613913922345),\n",
            "             ('best_exact_thresh', -8.192066669464111),\n",
            "             ('best_f1', 55.41563989117942),\n",
            "             ('best_f1_thresh', -4.551134943962097)])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}